# Predefined LLM models. Switch at runtime with /model in Telegram.
# The "model" field uses LiteLLM format: https://docs.litellm.ai/docs/providers
#
# Provider prefixes:
#   Ollama:   ollama_chat/<model>
#   OpenAI:   gpt-4o, gpt-4o-mini, o1-mini, ...
#   Gemini:   gemini/gemini-2.0-flash, gemini/gemini-2.5-pro, ...
#   Anthropic: claude-sonnet-4-5-20250929, ...

default: glm-4.7-flash

models:
  glm-4.7-flash:
    model: ollama_chat/glm-4.7-flash:latest
    provider: ollama
    description: "Llama 3 (local, via Ollama)"

  gemma3:
    model: ollama_chat/PetrosStav/gemma3-tools:27b
    provider: ollama
    description: "Gemma 3 (local, via Ollama)"

  qwen3-next:
    model: ollama_chat/qwen3-coder-next:latest
    provider: ollama
    description: "Qwen 3 Next (local, via Ollama)"

  gpt-4o-mini:
    model: gpt-4o-mini
    provider: openai
    description: "OpenAI GPT-4o Mini"

  gpt-4o:
    model: gpt-4o
    provider: openai
    description: "OpenAI GPT-4o"

  gemini-flash:
    model: gemini/gemini-3.0-flash
    provider: gemini
    description: "Google Gemini 3.0 Flash"

  gemini-pro:
    model: gemini/gemini-3.0-pro
    provider: gemini
    description: "Google Gemini 3.0 Pro"

  claude-sonnet:
    model: claude-sonnet-4-5-20250929
    provider: anthropic
    description: "Anthropic Claude Sonnet 4.5"
